default:
  tags:
    # Use an account that maps will switch users depending on the repo it
    # runs on
    - bb5_map
  interruptible: true

.gitlab_pipelines_variables:
  variables:
    # Default values for Slurm
    SLURM_OVERLAP: 1
    SALLOC_ACCOUNT: proj12
    SBATCH_ACCOUNT: proj12
    SLURM_ACCOUNT: proj12
    SALLOC_PARTITION: prod
    SBATCH_PARTITION: prod
    SLURM_PARTITION: prod
    # We never use the runner's native git checkout ability. We use `git clone`
    # explicitly to get Spack, and then Spack itself clones any projects we want
    # to build.
    GIT_STRATEGY: none
    # ${CI_BUILDS_DIR} will point to some {...}/{pipelineid} directory.
    bb5_build_dir: pipeline
    # Do not put the name of the repository in the working directory
    GIT_CLONE_PATH: ${CI_BUILDS_DIR}/J${CI_JOB_ID}
    # Make the top-level jobs launched by the GitLab CI use the same account
    bb5_account: proj12
    # Shared input directory for HPC integration tests.
    DATADIR: /gpfs/bbp.cscs.ch/project/proj12/jenkins

# Set up a clone of Spack for use in this pipeline and export a variable called
# SPACK_ROOT that points to it.
.spack_setup:
  stage: .pre
  extends: .gitlab_pipelines_variables
  variables:
    # What version of BlueBrain/spack to use. You can override this if need be.
    SPACK_BRANCH: develop
    # Which URL to use to check out spack
    SPACK_URL: https://github.com/BlueBrain/spack.git
  before_script:
    # Prefer the 2022 deployment modules.
    - unset MODULEPATH
    - . /gpfs/bbp.cscs.ch/ssd/apps/bsd/${SPACK_DEPLOYMENT_SUFFIX}/config/modules.sh
    - echo "MODULEPATH=${MODULEPATH}" > spack_clone_variables.env
    # If we are triggered by a PR on GitHub, fetch the body of the PR description
    - if [[ "${PARSE_GITHUB_PR_DESCRIPTIONS}" == "true" && "${CI_PIPELINE_SOURCE}" == "external_pull_request_event" ]]; then
    # Write a small Python script that queries the GitHub API and prints out a
    # series of variable declarations. See the README for documentation of the
    # required content of the GitHub PR description. The expressions in the PR
    # description are parsed into variables of the form:
    #  {package_name_upper}_{ref_type_upper}={ref}
    # where `ref_type` is one of `branch`, `tag` and `ref`, for example
    #  NEURON_BRANCH=some/feature-branch
    - |
      cat > parse_description.py << END_SCRIPT
      from __future__ import print_function
      import os
      import re
      import requests
      pr_info = requests.get("https://api.github.com/repos/{}/pulls/{}".format(
                              os.environ['CI_EXTERNAL_PULL_REQUEST_TARGET_REPOSITORY'],
                              os.environ['CI_EXTERNAL_PULL_REQUEST_IID']),
                             headers={'Accept': 'application/vnd.github.v3+json'})
      pr_body = pr_info.json()["body"]
      # match something like NEURON_BRANCH=foo/bar
      pat = re.compile('^([A-Z0-9_]+)_([A-Z]+)=([A-Z0-9\-\_\/\+]+)$', re.IGNORECASE)
      def parse_term(m):
        ref_type = m.group(2).lower()
        if ref_type not in {'branch', 'tag', 'ref'}: return
        print(m.group(1).upper() + '_' + ref_type.upper() + '=' + m.group(3))
      if pr_body is not None:
        for pr_body_line in pr_body.splitlines():
          if not pr_body_line.startswith('CI_BRANCHES:'): continue
          for config_term in pr_body_line[12:].split(','):
            pat.sub(parse_term, config_term)
      END_SCRIPT
    # GitLab's UI collapses the multi-line command above so this aids debugging
    - cat parse_description.py
    # Save the variables we parsed out of the GitHub PR body for later jobs.
    - (module load unstable python-dev; python parse_description.py) >> spack_clone_variables.env
    # Load them into the environment of the current job -- this should align
    # things between the case that we are triggered by a GitHub PR and the case
    # where we are triggered manually/as a child on GitLab.
    - . spack_clone_variables.env
    # For debugging
    - cat spack_clone_variables.env
    # endif that we're triggered by a PR on GitHub
    - fi
  script:
    - echo Preparing to clone Spack into ${PWD}
    - if [[ -z "${SPACK_BRANCH}" && ( -n "${SPACK_COMMIT}" || -n "${SPACK_TAG}" ) ]]; then
    - echo "Spack ref must be a branch (BRANCH=${SPACK_BRANCH}, COMMIT=${SPACK_COMMIT}, TAG=${SPACK_TAG})"
    - fi
    - echo Checking out the ${SPACK_BRANCH} of Spack...
    - git clone --depth 1 --single-branch --branch ${SPACK_BRANCH} ${SPACK_URL} spack
    - SPACK_ROOT=${PWD}/spack
    - rm -f ${SPACK_ROOT}/etc/spack/*.yaml
    - cp ${SPACK_ROOT}/bluebrain/sysconfig/bluebrain5/*.yaml ${SPACK_ROOT}/etc/spack
    - echo "SPACK_ROOT=${SPACK_ROOT}" >> spack_clone_variables.env
    - echo "SPACK_BRANCH=${SPACK_BRANCH}" >> spack_clone_variables.env # might be the default from this job
    - echo "SPACK_SYSTEM_CONFIG_PATH=/gpfs/bbp.cscs.ch/ssd/apps/bsd/${SPACK_DEPLOYMENT_SUFFIX}/config" >> spack_clone_variables.env
    - echo "SPACK_USER_CACHE_PATH=${CI_BUILDS_DIR}" >> spack_clone_variables.env
    - export $(cat spack_clone_variables.env | xargs)
    - . ${SPACK_ROOT}/share/spack/setup-env.sh
    # Trigger bootstrapping and so on, check everything looks OK
    - spack spec -IL ninja
  artifacts:
    when: always
    paths: [spack_clone_variables.env]
    reports:
      dotenv: spack_clone_variables.env

# Augmented version of .spack_setup that additionally enables ccache in the
# Spack configuration and exports a variable SPACK_USE_CCACHE=true for use in
# later stages.
.spack_setup_ccache:
  extends: .spack_setup
  script:
    - !reference [.spack_setup, script]
    # Enable ccache
    - spack config --scope site add "config:ccache:true"
    # In principle later stages could use some kind of
    # `spack config get config | grep ccache` construction, but this is simpler
    - echo "SPACK_USE_CCACHE=true" >> spack_clone_variables.env

.spack_build:
  extends: .gitlab_pipelines_variables
  stage: build
  variables:
    # By default we update the `develop` version of the Spack recipe to point
    # to this commit ("the commit the pipeline is being run on"). This variable
    # can be overriden, also with tag="..." or branch="...".
    SPACK_PACKAGE_REF: commit="${CI_COMMIT_SHA}"
  before_script:
    # Change the staging directory to something specific to this GitLab CI job.
    # This stops Spack from cleaning up previous build directories, which
    # causes errors if you try to run "test:library" in parallel with
    # "build:application_that_depends_on_library".
    - SPACK_BUILD="${PWD}/spack-build"
    # Dump the environment for debugging purposes
    - env -0 | sort -z | xargs -0 -L 1 echo > initial_environment.env
    # SPACK_ROOT is passed in by the dotenv artifacts of a previous job.
    - . ${SPACK_ROOT}/share/spack/setup-env.sh
    # Tell Spack which working directory to use in this job. It would be nice
    # if this first part could be done with `spack config add`...
    - export SPACK_USER_CONFIG_PATH=${PWD}/spack-config
    - mkdir ${SPACK_USER_CONFIG_PATH}
    - |
      cat > ${SPACK_USER_CONFIG_PATH}/config.yaml << END_SCRIPT
      config:
        build_stage::
        - ${SPACK_BUILD}
        source_cache: ${PWD}/spack-source-cache
      END_SCRIPT
    - spack config blame config
    - if [ "${SPACK_EXPORT_SPECS}" ]; then
    - spack export --scope=command_line --module tcl ${SPACK_EXPORT_SPECS} > ${SPACK_USER_CONFIG_PATH}/packages.yaml
    - cat ${SPACK_USER_CONFIG_PATH}/packages.yaml
    - fi
    # Tell Git how to re-write BBP GitLab URLs to use a token instead of SSH
    - export XDG_CONFIG_HOME=${PWD}/local_config
    - mkdir -p "${XDG_CONFIG_HOME}/git"
    - echo -e "[url \"https://gitlab-ci-token:${CI_JOB_TOKEN}@bbpgitlab.epfl.ch/\"]\n  insteadOf = git@bbpgitlab.epfl.ch:" > "${XDG_CONFIG_HOME}/git/config"
    - cat "${XDG_CONFIG_HOME}/git/config"
    # Figure out what the develop version of this package should refer to. If
    # this was steered by the PR description or otherwise using
    # PACKAGE_{BRANCH,COMMIT,TAG} variables then we should respect those.
    # Otherwise, just use the SPACK_PACKAGE_REF value.
    - for ref in tag commit branch; do
    -   var_name="${SPACK_PACKAGE^^}_${ref^^}"
    -   if [[ -n "${!var_name}" ]]; then
    -     SPACK_PACKAGE_REF="${ref}='${!var_name}'"
    -     echo "Set SPACK_PACKAGE_REF=${SPACK_PACKAGE_REF} from ${var_name}=${!var_name}"
    -     break
    -   fi
    - done
    # Modify the Spack recipe so the develop version points at ${SPACK_PACKAGE_REF}
    - SPACK_PACKAGE_FILE="$(spack location -p ${SPACK_PACKAGE})/package.py"
    # Remove any commit/tag/branch identifier from the line containing the
    # develop version and substitute in our desired commit hash. Don't
    # change anything if ${SPACK_PACKAGE_REF} is unset or an empty string.
    - if [ "${SPACK_PACKAGE_REF}" ]; then
    - echo New ref for ${SPACK_PACKAGE} is ${SPACK_PACKAGE_REF}
    # Note that [^\2] doesn't work, backreferences are not expanded there, so
    # we have to use [^\"'].
    - sed -i -e "/^\s*version\s*(\s*\(['\"]\)develop\1/ { s/,\s*\(commit\|tag\|branch\)=\([\"']\)[^\"']\+\2//g; s#)#, ${SPACK_PACKAGE_REF})#; }" "${SPACK_PACKAGE_FILE}"
    - (cd $(dirname "${SPACK_PACKAGE_FILE}") && git diff "${SPACK_PACKAGE_FILE}")
    - fi
    # Get the hash of the version we're about to install. First, construct the
    # full spec. This includes ${SPACK_PACKAGE_COMPILER} and ${SPACK_PACKAGE_DEPENDENCIES} if
    # they are not empty.
    - SPACK_FULL_SPEC="${SPACK_PACKAGE}@develop${SPACK_PACKAGE_COMPILER:+%}${SPACK_PACKAGE_COMPILER}${SPACK_PACKAGE_SPEC}${SPACK_PACKAGE_DEPENDENCIES:+ }${SPACK_PACKAGE_DEPENDENCIES}"
    - echo "Preparing to install ${SPACK_FULL_SPEC}"
    # Then extract the hash
    - JSON_SPEC=$(spack spec --json ${SPACK_FULL_SPEC})
    - SPACK_INSTALLED_HASH=$(module load unstable python; echo "${JSON_SPEC}" | python -c "import json, sys; print(json.loads(sys.stdin.read())[\"spec\"][\"nodes\"][0][\"hash\"])")
    - echo "Determined its hash will be ${SPACK_INSTALLED_HASH}"
    # Construct the directories Spack is going to use to build the package.
    # For a CMake project the source directory will be:
    #   ${SPACK_STAGE_DIR}/spack-src
    # and the build directoy will by default be
    #   ${SPACK_STAGE_DIR}/spack-build-{short_hash}
    # TODO: to improve ccache support, drop the {short_hash} part. This needs a
    # change to `cmake.py` in Spack.
    - SPACK_STAGE_DIR=${SPACK_BUILD}/spack-stage-${SPACK_PACKAGE}-develop-${SPACK_INSTALLED_HASH}
    - SPACK_BUILD_DIR=${SPACK_STAGE_DIR}/spack-build-${SPACK_INSTALLED_HASH:0:7}
    - SPACK_SOURCE_DIR=${SPACK_STAGE_DIR}/spack-src
    # ccache-specific setup, only if it was enabled
    - if [ ${SPACK_USE_CCACHE+x} ]; then
    # Load a more modern ccache version.
    - module load unstable ccache
    # Tell ccache to use paths relative to this directory, to avoid polluting
    # the cache with pipeline- and job-specific paths.
    - export CCACHE_BASEDIR=$(realpath -P ${CI_BUILDS_DIR})
    - echo CCACHE_BASEDIR=${CCACHE_BASEDIR}
    # Default is 5G. There is no automatic cleaning of the caches on the GitLab
    # side, so this is a good way of stopping things from growing too much.
    - export CCACHE_MAXSIZE=512M
    # For debugging cache misses.
    # - export CCACHE_DEBUG=true
    # - export CCACHE_DEBUGDIR=${CI_PROJECT_DIR}/ccache_debug/
    # We can't assume there was a valid GitLab cache, so create empty
    # directories if needed.
    - export CCACHE_DIR="${TMPDIR}/ccache"
    - mkdir -p ${CCACHE_DIR}
    - if [ -f ${CI_PROJECT_DIR}/ccache.tar ]; then
    # There was a valid cache from GitLab
    - tar -C "${CCACHE_DIR}" -xf "${CI_PROJECT_DIR}/ccache.tar"
    - fi
    # Zero the statistics.
    - ccache --zero-stats
    - ccache --show-stats --verbose
    - fi
    # end ccache-specific setup
  script:
    # Spack needs a recent Git version. It possible to load additional
    # modules through the SPACK_EXTRA_MODULES environment variable.
    - module load unstable git ${SPACK_EXTRA_MODULES}
    # *Un*install this spec first. This can be helpful when resubmitting failed
    # jobs, for example if the GitLab job finalisation fails then the package
    # might have been successfully installed to the pipeline's Spack tree. Also
    # include `--dependents` so that if we are installing `lib` and then `app`
    # that depends on it then re-trying to build `lib` after `app` has been
    # installed will uninstall both `lib` and `app` instead of neither.
    - spack uninstall -y --dependents /${SPACK_INSTALLED_HASH} || true
    # Show what we're going to do, ignore the duplication with `spack spec`
    # above for now
    - spack spec -Il ${SPACK_FULL_SPEC}
    # Install that new version. Use an absolute path for install.xml so it ends
    # up in the original job working directory even if that's no longer the
    # working directory.
    - spack ${SPACK_INSTALL_EXTRA_FLAGS} install -j${SLURM_CPUS_PER_TASK} --log-format=junit --log-file=${CI_PROJECT_DIR}/install.xml --keep-stage ${SPACK_FULL_SPEC} || install_failed=1
    # Try and improve debuggability, Spack likes making things only-owner-readable.
    - chmod -R g+rX "${SPACK_BUILD}"
    # Exit if we failed just above.
    - if [[ ${install_failed} == 1 ]]; then exit 1; fi
    - if [ ${SPACK_USE_CCACHE+x} ]; then
    # Report ccache statistics if ccache was enabled.
    - ccache --cleanup
    - ccache --show-stats --verbose
    # Create the cache archive for GitLab to handle. Intentionally do not compress (again) here.
    - tar -C "${CCACHE_DIR}" -cf "${CI_PROJECT_DIR}/ccache.tar" .
    - fi
    # Copy some files to the original working directory that artifacts are
    # saved from.  Make sure that optional files exist.
    - touch ${SPACK_STAGE_DIR}/spack-configure-args.txt
    - cp ${SPACK_STAGE_DIR}/spack-{build-env,build-out,configure-args}.txt ${CI_PROJECT_DIR}/
    # NOTE changed behaviour. Before we would append ^/new_hash to the
    # SPACK_PACKAGE_DEPENDENCIES variable. This produced a rather long spec for
    # the later stages of a chain of build jobs, and also included any extra
    # specs that were specified manually along the way, i.e. for A <- B <- C
    #   ^dep_of_A+variant^/hash_of_A^dep_of_B%gcc^/hash_of_B
    # Now we just include ^/hash_of_B in SPACK_PACKAGE_DEPENDENCIES after
    # building B, and trust that that encodes all relevant constraints.
    - SPACK_PACKAGE_DEPENDENCIES=^/${SPACK_INSTALLED_HASH}
    # Record the git commit that we actually used when building this package
    - SPACK_PACKAGE_COMMIT=$(cd ${SPACK_SOURCE_DIR} && git rev-parse HEAD)
    - echo The develop version mapped onto commit ${SPACK_PACKAGE_COMMIT} in this case, saving that to SPACK_PACKAGE_COMMIT and SPACK_${SPACK_PACKAGE^^}_COMMIT.
    # Overwrite the spack_build_info.env file, otherwise chains of dependent
    # build jobs will duplicate these values.
    - echo "SPACK_BUILD_DIR=${SPACK_BUILD_DIR}" > ${CI_PROJECT_DIR}/spack_build_info.env
    - echo "SPACK_FULL_SPEC=${SPACK_FULL_SPEC}" >> ${CI_PROJECT_DIR}/spack_build_info.env
    - echo "SPACK_SOURCE_DIR=${SPACK_SOURCE_DIR}" >> ${CI_PROJECT_DIR}/spack_build_info.env
    - echo "SPACK_INSTALLED_HASH=${SPACK_INSTALLED_HASH}" >> ${CI_PROJECT_DIR}/spack_build_info.env
    - echo "SPACK_PACKAGE_COMMIT=${SPACK_PACKAGE_COMMIT}" >> ${CI_PROJECT_DIR}/spack_build_info.env
    - echo "SPACK_${SPACK_PACKAGE^^}_COMMIT=${SPACK_PACKAGE_COMMIT}" >> ${CI_PROJECT_DIR}/spack_build_info.env
    - echo "SPACK_PACKAGE_DEPENDENCIES=${SPACK_PACKAGE_DEPENDENCIES}" >> ${CI_PROJECT_DIR}/spack_build_info.env
    # Return a meaningful status code by inspecting install.xml. This only
    # loads modules in a subshell so it doesn't pollute the environment. The
    # snippet counts the number of <failure> tags in the XML.
    - num_failures=$(module load unstable python-dev; python -c "from lxml import etree; xml = etree.parse('${CI_PROJECT_DIR}/install.xml'); print(sum(1 for _ in xml.getroot().iter('failure')) + sum(1 for _ in xml.getroot().iter('error')))")
    - echo "Returning the number of failed builds, ${num_failures}"
    - exit ${num_failures}
  needs: ["spack_setup"]
  artifacts:
    when: always
    paths:
      - install.xml
      - spack_build_info.env
      - spack_clone_variables.env
      - initial_environment.env
      - spack-build-env.txt
      - spack-build-out.txt
      - spack-configure-args.txt
    reports:
      junit: install.xml
      dotenv:
        - spack_build_info.env
        - spack_clone_variables.env
  cache:
    key: ${CI_JOB_NAME}
    paths: [ccache.tar]
    policy: pull-push

.spack_test:
  extends: .gitlab_pipelines_variables
  stage: test
  variables:
    # Just running tests, no need to check anything out
    GIT_STRATEGY: none
    # Run tests with many 1-core tasks instead of 1 many-core task, as this
    # means that naive `mpirun -n ...` should work.
    bb5_ntasks: 8
    bb5_cpus_per_task: 1
  before_script:
    # Dump the environment for debugging purposes
    - env -0 | sort -z | xargs -0 -L 1 echo > initial_environment.env
    # Tell CTest to use the available slots. This may not quite be correct if
    # the tasks are allocated across several nodes.
    - export CTEST_PARALLEL_LEVEL=${SLURM_TASKS_PER_NODE}
    # Load the Spack installation that knows about the package to be tested.
    - . ${SPACK_ROOT}/share/spack/setup-env.sh
  script:
    - spack load ${SPACK_FULL_SPEC}
    - sh ${SPACK_SOURCE_DIR}/.ci/test_${CI_JOB_NAME}.sh
  artifacts:
    when: always
    paths:
      - initial_environment.env

.ctest:
  extends: .spack_test
  script:
    # Change to the build directory of the package being tested. This is
    # somewhere under the working directory of a previous job in the pipeline.
    - cd ${SPACK_BUILD_DIR}
    # Yuck, but otherwise boost unit tests output colour codes as part of
    # ctest -VV and the XML translation fails.
    - export BOOST_TEST_COLOR_OUTPUT=no
    # Make sure we return a helpful exit code.
    - i_am_a_failure=0
    # --output-on-failure should stop the output from parallel jobs being
    # interleaved. The full logfile including output from all jobs is uploaded
    # as an artefact, so we shouldn't lose any information.
    - spack build-env ${SPACK_FULL_SPEC} -- ctest --output-on-failure -T Test || i_am_a_failure=1
    # Save the Testing/ directory as job artifacts
    - cp -r Testing/ ${CI_PROJECT_DIR}/
    # Make an XML report file the GitLab UI can display
    - module load unstable unit-test-translator
    - cmake2junit > ${CI_PROJECT_DIR}/ctest.xml
    - exit ${i_am_a_failure}
  artifacts:
    when: always
    paths:
      # Ugly to re-declare this from .spack_test, but oh well.
      - initial_environment.env
      - Testing/
    reports:
      junit: ctest.xml
